<p>The NUJ has updated its policy on the use of artificial intelligence in journalism, setting out clear principles to protect journalists' rights and the integrity of news content.</p>

<h2>Key Policy Positions</h2>
<ul>
    <li><strong>Consent and compensation</strong>: Publishers must not use journalists' work to train AI models without explicit consent and fair compensation.</li>
    <li><strong>Transparency</strong>: All AI-generated or AI-assisted content must be clearly labelled for readers.</li>
    <li><strong>No replacement</strong>: AI tools should augment journalists' work, not replace journalists. Newsrooms must not use AI as a pretext for redundancies.</li>
    <li><strong>Editorial oversight</strong>: All AI-generated content must be reviewed and verified by a human journalist before publication.</li>
    <li><strong>Data protection</strong>: AI tools used in newsrooms must comply with GDPR and not compromise sources or sensitive information.</li>
</ul>

<h2>What This Means for Members</h2>
<p>If your employer is introducing AI tools in the newsroom, the NUJ recommends:</p>
<ol>
    <li>Request a chapel meeting to discuss the introduction of AI tools</li>
    <li>Negotiate an AI agreement through your chapel or workplace representative</li>
    <li>Ensure your contract protects your copyright in the context of AI training</li>
    <li>Report any concerns about AI replacing editorial jobs to the NUJ</li>
</ol>

<p>The London Central Branch supports the NUJ's position and encourages all members to stay informed about AI developments in their workplaces.</p>
